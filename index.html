<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Tianhao Cheng (ç¨‹å¤©è±ª)</title>

  <meta name="author" content="Xinyu Huang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon"
    href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸ‘¾</text></svg>">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Tianhao Cheng (ç¨‹å¤©è±ª)</name>
                  </p>
                  <p>I am a second-year master student at <a href="https://cs.fudan.edu.cn/"> the School of Computer
                      Science Fudan University</a>, advised by
                    Prof. <a href="https://faculty.fudan.edu.cn/fengrui/zh_CN/index.htm">Rui Feng</a>. I'm honored to be
                    guided by Professor <a href="https://bigaidream.github.io/">Fujie</a>.
                    Also, I'm a research intern at <a href="https://www.stepfun.com/">stepfun</a> with Researcher <a
                      href="https://commencement.github.io/">Zili Wang</a> focusing on foundation model.
                  </p>
                  <p>
                    <!-- My research interests include computer vision and multi-modality. I created the <a href="https://github.com/xinyu1205/recognize-anything" style="color: red;">Recognize Anything Model (RAM) Family</a>, which is a series of open-source and powerful image recognition models. -->
                    My research interests include LLM (pretrain, post-train), system-2 LLMs. I'm the co-first author of <a href="https://github.com/OpenCoder-llm/OpenCoder-llm">OpenCoder</a>, a top-tier codeLLM.I'm also the member of <a
                      href="https://github.com/infly-ai/INF-LLM">INF-34B</a> pretrain team, focusing on code part.
                  </p>
                  <p>
                    <!-- <strong>I expect to graduate at June 2025. I am opening to both academic positions and industrial research positions. Kindly download my <a href="images/resume_xinyuhuang.pdf">Resume</a>, and do not hesitate to email me if you're interested :)</strong> -->
                    It's fun to seek the principles underlying the dark magic. AGI belongs to those who love it :-) Feel free to contact me through email.
                  </p>
                  <p style="text-align:center">
                    <!--                 <a href="images/resume_xinyuhuang.pdf">Resume</a> &nbsp/&nbsp -->
                    <a href="mailto:thcheng23@m.fudan.edu.cn">Email</a> &nbsp/&nbsp
                    <a href="https://scholar.google.com/citations?user=LwvEAgoAAAAJ&hl=zh-CN">Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/crazycth">Github</a> &nbsp/&nbsp
                    <a href="https://www.zhihu.com/people/yi-jin-ye-xing-4-38">Zhihu</a>
                  </p>
                  <!-- </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/xinyuhuang.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xinyuhuang.jpg" class="hoverZoomLink"></a>
            </td> -->
                <td style="padding:1.5%;width:40%;max-width:40%">
                  <a href="images/æˆ‘.png"><img style="width:80%;max-width:80" alt="profile photo" src="images/æˆ‘.png"
                      class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <!-- <heading>Research</heading>(* indicates equal contribution) -->
                  <heading>Research</heading> (* indicates equal contribution)
                </td>
              </tr>
            </tbody>
          </table>
          <style>
            img {
              border-radius: 15px;
            }
          </style>
      
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/image.png" alt="OpenCoder" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://opencoder-llm.github.io/">
                  <papertitle> <br>OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models
                  </papertitle>
                  </a>
                  <br>
                  Siming Huang*, <strong>Tianhao Cheng*</strong>, Jason Klein Liu, Jiaran Hao, Liuyihan Song, Yang Xu, J. Yang, J.H. Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Zhaoxiang Zhang, Jie Fu, Qian Liu, Ge Zhang, Zili Wang<sup>â€ </sup>, Yuan Qi, Yinghui Xu, Wei Chu<sup>â€ </sup>
                  <br>
                  <strong><em>Arxiv</em></strong>
                  <br>
                  <a href="https://opencoder-llm.github.io/">Home Page</a>
                  /
                  <a href="https://arxiv.org/abs/2411.04905">Paper</a>
                  /
                  <a href="https://github.com/OpenCoder-llm/OpenCoder-llm">Github</a>
                  /
                  <a href="https://huggingface.co/OpenCoder-LLM">Huggingface</a>
                  /
                  <a href="https://zhuanlan.zhihu.com/p/8054507241">Zhihu</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/INF-LLM2.png" alt="INF34B" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://github.com/infly-ai/INF-LLM">
                  <papertitle> <br>INF-34B: INFâ€™s Open-Source Large Language Models
                  </papertitle>
                  </a>
                  <br>
                  Jiaran Hao, Zili Wang, Siming Huang, <strong>Tianhao Cheng</strong>, LiuYihan Song, Ansheng You, Zhipeng Zhou, Xiaoyu Tan, Dakuan Lu, Xiaoming Shi, Chao Qu, Haozhe Wang, Yinghui Xu, Wei Chu, Yuan Qi
                  <br>
                  <a href="https://www.infly.cn/zh/research"><strong><em>INF Website</em></strong></a>
                  <br>
                  <a href="https://s.infly.cn/f/img/pdf/inf_34b_tech_report.pdf">Paper</a>
                  /
                  <a href="https://github.com/infly-ai/INF-LLM">Github</a>
                  /
                  <a href="https://huggingface.co/infly/INF-34B-Chat">Huggingface</a>
                  <p></p>
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/nature.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2310.15200">
                    <!-- <papertitle> Recognize Anything Plus Model (RAM++) </papertitle> -->
                  </a>
                  <papertitle> <br> RETFound-enhanced community-based fundus disease screening: real-world evidence and
                    decision curve analysis </papertitle>
                  <br>
                  Juzhao Zhang*, Senlin Lin*, <strong>Tianhao Cheng*</strong>, Yi Xu, Lina Lu, Jiangnan He, Tao Yu,
                  Yajun Peng, Yuejie Zhang, Haidong Zhou, Yingyan Ma
                  <br>
                  <em>npj Digital Medicine (NATURE RESEARCH, IF 12.4)</em>
                  <br>
                  <!-- <a href="https://recognize-anything.github.io/">project page</a> -->

                  <a href="https://www.nature.com/articles/s41746-024-01109-5">paper</a>
                  /
                  <a
                    href="https://github.com/Akemimadokami/DL-Model-for-Community-based-Fundus-Disease-Screening">code</a>
                  <p></p>
                  <!-- <p>RAM++ is the next generation of RAM, which can <strong>recognize any category with high accuracy</strong>, including <strong>both predefined common categories and diverse open-set categories</strong>.    </p> -->
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/P2Med.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://arxiv.org/abs/2310.15200">
                    <!-- <papertitle> Recognize Anything Plus Model (RAM++) </papertitle> -->
                  </a>
                  <papertitle> <br> A Medical Multimodal Large Language Model for Pediatric Pneumonia </papertitle>
                  <br>
                  Weiwei Tian, Xinyu Huang, <strong>Tianhao Cheng*</strong>, Wen He, Jinwu Fang, Rui Feng, 
                  Xiaobo Zhang
                  <br>
                  <strong><em>Arxiv</em></strong>
                  <br>
                  <!-- <a href="https://recognize-anything.github.io/">project page</a> -->

                  <a href="https://arxiv.org/abs/2409.02608">paper</a>
                  <!-- / -->
                  <!-- <a
                    href="https://github.com/Akemimadokami/DL-Model-for-Community-based-Fundus-Disease-Screening">code</a> -->
                  <!-- <p>RAM++ is the next generation of RAM, which can <strong>recognize any category with high accuracy</strong>, including <strong>both predefined common categories and diverse open-set categories</strong>.    </p> -->
                </td>
              </tr>

            </tbody>
          </table>


          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Projects & Resources</heading>
                </td>
              </tr>
            </tbody>
          </table>


              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/YiVal.png" alt="tag2text" width="190" height="110">
                    </td>
                    <td width="75%" valign="middle">
                      <a href="https://github.com/YiVal/YiVal">
                        <papertitle> YiVal: Automatic Prompt Engineering Assistant </papertitle>
                      </a>
                      <br>
                      <strong>Project Co-Leader & Main Contributor (1w+ lines code contribution)</strong>
                      <br>
                      <span style="color: red;">2.5K+ stars! </span>
                      <p></p>
                      <p>YiVal is a framework designed for <strong>prompt engineering</strong> especially in
                        <strong>auto-prompting</strong></p>
                      <p>Fun FactðŸŒŸ: This was my first startup experience. We ultimately failed, but I love the feeling
                        of business. </p>
                    </td>
                  </tr>
                </tbody>
              </table>

            <table
              style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading>Professional Experiences</heading>
                  </td>
                </tr>
              </tbody>
            </table>

            <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/step.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <papertitle>StepFun: NLP Research Intern</papertitle>
                  <br>
                  Dec 2024 - CURRENT
                  <br>
                  Foudation Model Research Intern
                  <br>
                  <br>
                  Explore. Feedback. Learn.
                  
                  <br>
                  <br>
                  The best verifier is the world itself.
                </td>
               </tr>


              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/INFLOGO.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <!-- <a href="https://recognize-anything.github.io/"> -->
                    <!-- <papertitle> Recognize Anything Model (RAM) </papertitle> -->
                  <!-- </a> -->
                  <papertitle>INFTech: NLP Research Intern</papertitle>
                  <br>
                  Jun 2024 - Nov 2024
                  <br>
                  Research Intern at the Base-Model group, supervised by <a href="https://commencement.github.io/">Zili Wang</a>
                  <br>
                  <br>
                   I'm the co-first author of OpenCoder. Pretrain is a lot like building a nuclear bomb.
                </td>
               </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/yival_logo.png" alt="tag2text" width="120" height="120">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://recognize-anything.github.io/">
                    <!-- <papertitle> Recognize Anything Model (RAM) </papertitle> -->
                  </a>
                  <papertitle>YiVal: Algorithm Engineer </papertitle>
                  <br>
                  July 2023 - Jun 2024
                  <br>
                  Core Developer for <a href="https://github.com/YiVal/YiVal">yival (2.5k+ star)</a>, 1w+ lines code contribute
                  <br>
                  Research & Paper Implement: Survey and implement automatic-prompt-eng methods in yival
                  <br>
                  <br>
                   During my frontend internship, I found prompt engineering too tedious, so I decided to automate <strong>prompt design | evol | evaluate</strong>.
                   YiVal was my first entrepreneurial venture, but I finally quit due to some ideological differences.
                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/bytedance.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <papertitle>ByteDance: LAB-NLP Backend Engineer (Model Inference) Intern </papertitle>
                  <br>
                  Feb 2023 - Jun 2023
                  <br>
                  Engineer Intern at LAB-NLP
                  <br>
                  I developed the team's first inference serving framework based on FastTransformer
                  <br>
                  <br>
                  ðŸ’ª This internship made me aware of the gap between myself and others ðŸ’ª

                </td>
              </tr>

              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/bytedance.png" alt="tag2text" width="190" height="110">
                </td>
                <td width="75%" valign="middle">
                  <a href="https://recognize-anything.github.io/">
                    <!-- <papertitle> Recognize Anything Model (RAM) </papertitle> -->
                  </a>
                  <papertitle>ByteDance: Life-Service Backend Engineer Intern </papertitle>
                  <br>
                  May 2022 - Dec 2022
                  <br>
                  Develop Tiktok Anchor Recommendation Framework, supervised by <a href="https://www.linkedin.com/in/%E4%BA%8C%E6%98%8E-%E6%9D%A8-14734a137/?originalSubdomain=cn">Rico Eric</a>
                  <br>
                  <br>
                  My greatest achievement is learning how to <strong>solve problems independently</strong>. I was happy to find myself growing into a <strong>reliable</strong> engineer. 
                </td>
              </tr>

            </tbody>
          </table>



          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Educational Experiences</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table
          style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-left:40px;">
          <tbody>
            <tr>
              <td style="padding:20px;width:25%;vertical-align:middle">
                <img src="images/fdu.png" alt="tag2text" width="110" height="110">
              </td>
              <td width="75%" valign="middle" stype="padding:50px">
                <a href="https://recognize-anything.github.io/">
                  <!-- <papertitle> Recognize Anything Model (RAM) </papertitle> -->
                </a>
                <papertitle>Fudan University</papertitle>
                <br>
                Sep 2023 - Present
                <br>

                Master in Computer Science
                <br>
                <br>

                Member of CMIT.
                <br>
              </td>
            </tr>
          </tbody>
        </table>
          
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:40px;">
            <tbody>
              <tr>
                <td style="padding:20px;width:25%;vertical-align:middle">
                  <img src="images/shu.png" alt="tag2text" width="110" height="110">
                </td>
                <td width="75%" valign="middle" stype="padding:50px">
                  <a href="https://recognize-anything.github.io/">
                    <!-- <papertitle> Recognize Anything Model (RAM) </papertitle> -->
                  </a>
                  <papertitle>Shanghai University</papertitle>
                  <br>
                  Sep 2019 - July 2023
                  <br>

                  B.S. in Computer Science
                  <br>
                  GPA: 3.91/4.00, ranking: 1/163
                  <br>
                  <br>
                  Member of SHU ACM Training Team,  Leader of <i>Well-Prepared Team</i>
                  <br>
                  These are my <strong>golden hours</strong>
                  <br>
                </td>
              </tr>
            </tbody>
          </table>

          

            
<!-- 
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle; ">
                  <heading>Selected Awards</heading>
                </td>
              </tr>

              <tr>
                <td>
                  <ul>
                    <li>First Prize Scholarship, Fudan University <span class="date">2023</span></li>
                    <li>Scholarship of Huawei Intelligent Center Program <span class="date">2022</span></li>
                    <li>Outstanding Graduates of Shanghai <span class="date">2023</span></li>
                    <li>ðŸ¥ˆSilver Medal of <a href="https://www.ccf.org.cn/ccsp/">CCSP</a> 2021</li>
                    <li>ðŸ¥ˆSilver Medal of <a href="https://ccpc.io/">ACM-CCPC</a> Guangzhou Station 2021</li>
                    <li>ðŸ¥‰Bronze Medal of <a href="https://icpc.global/">ACM-ICPC</a> Shenyang Station, 2021</li>
                    <li>ðŸ¥ˆSecond Prize of <a href="http://www.mcm.edu.cn/">China Undergraduate Mathematical Contest in Modeling</a>, 2021 </li>
                    <li>Outstanding Academic Scholarship, Shanghai University <span class="date">2019 & 2020 & 2021</span></li>
                    <li>Outstanding Student, Shanghai University <span class="date">2019 & 2020</span></li>
                </ul>
                </td>
              </tr>
            </tbody>
          </table> -->

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle; margin-bottom: 0px;">
                  <heading style="display: block; margin: 0px;">Selected Awards</heading>
                </td>
              </tr>

              <tr>
                <td style="padding:0px;">
                  <ul style="margin-top: 5px;">
                    <li>First Prize Scholarship, Fudan University <span class="date">2023</span></li>
                    <li>Scholarship of Huawei Intelligent Center Program <span class="date">2022</span></li>
                    <li>Outstanding Graduates of Shanghai <span class="date">2023</span></li>
                    <li>ðŸ¥ˆSilver Medal of <a href="https://www.ccf.org.cn/ccsp/">CCSP</a> 2021</li>
                    <li>ðŸ¥ˆSilver Medal of <a href="https://ccpc.io/">ACM-CCPC</a> Guangzhou Station 2021</li>
                    <li>ðŸ¥‰Bronze Medal of <a href="https://icpc.global/">ACM-ICPC</a> Shenyang Station, 2021</li>
                    <li>ðŸ¥ˆSecond Prize of <a href="http://www.mcm.edu.cn/">China Undergraduate Mathematical Contest in Modeling</a>, 2021 </li>
                    <li>Outstanding Academic Scholarship, Shanghai University <span class="date">2019 & 2020 & 2021</span></li>
                    <li>Outstanding Student, Shanghai University <span class="date">2019 & 2020</span></li>
                  </ul>
                </td>
              </tr>
            </tbody>
          </table>



        </td>
      </tr>

      <h2 style="CLEAR: both;"></h2>
      <script type="text/javascript" id="clustrmaps" 
      src="//clustrmaps.com/map_v2.js?d=0MR5uesZjfPI7YeX0flw1xHWcwGVol-FCRcfFdgQvfs&cl=080808&w=300&t=tt&co=ffffff&cmo=3acc3a&cmn=ff5353&ct=808080">
      </script>    

  </table>
</body>
</html>